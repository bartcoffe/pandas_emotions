{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD A DATASET WITH ALL FEATURES: PROCEDURE, AFFECTIVE SCORE, EMOTIONS, PERSONALITY ETC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import mean,std\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import RepeatedKFold,cross_val_score,KFold,train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,MultiLabelBinarizer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error,accuracy_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv2D,Activation,Flatten,MaxPooling2D\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.utils import normalize, to_categorical\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "path='emo_personality_procedure_df.csv'\n",
    "df_full = pd.read_csv(path,converters={'SEC_EMO': eval,'FIRST_EMO':eval})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUB_NAME</th>\n",
       "      <th>STIMULI</th>\n",
       "      <th>FRAME_NUMBER</th>\n",
       "      <th>IADS_ID</th>\n",
       "      <th>IAPS_ID</th>\n",
       "      <th>ANGER</th>\n",
       "      <th>CONTEMPT</th>\n",
       "      <th>DISGUST</th>\n",
       "      <th>FEAR</th>\n",
       "      <th>HAPPINESS</th>\n",
       "      <th>NEUTRAL</th>\n",
       "      <th>SADNESS</th>\n",
       "      <th>SURPRISE</th>\n",
       "      <th>FIRST_EMO</th>\n",
       "      <th>SEC_EMO</th>\n",
       "      <th>MEAN_ABS_ERR</th>\n",
       "      <th>MEAN_SQ_ERR</th>\n",
       "      <th>ENERGY</th>\n",
       "      <th>WASSERSTEIN</th>\n",
       "      <th>RELATIVE_ENTROPY</th>\n",
       "      <th>JENSENSHANNON</th>\n",
       "      <th>HELLINGER</th>\n",
       "      <th>BHATTACHARYYA_DIST</th>\n",
       "      <th>CORRELATION</th>\n",
       "      <th>COND</th>\n",
       "      <th>ANS_VALENCE</th>\n",
       "      <th>ANS_AROUSAL</th>\n",
       "      <th>OPENNESS</th>\n",
       "      <th>CONSCIENTIOUSNESS</th>\n",
       "      <th>NEUROTICISM</th>\n",
       "      <th>AGREEABLENESS</th>\n",
       "      <th>EXTRAVERSION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>SUB103</td>\n",
       "      <td>SUB103_102_None</td>\n",
       "      <td>300</td>\n",
       "      <td>102</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[NEUTRAL]</td>\n",
       "      <td>[CONTEMPT]</td>\n",
       "      <td>0.052750</td>\n",
       "      <td>0.010922</td>\n",
       "      <td>0.116190</td>\n",
       "      <td>0.052750</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.281714</td>\n",
       "      <td>0.334280</td>\n",
       "      <td>0.118494</td>\n",
       "      <td>3.436184e-02</td>\n",
       "      <td>S0</td>\n",
       "      <td>6.582</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>SUB103</td>\n",
       "      <td>SUB103_102_None</td>\n",
       "      <td>195</td>\n",
       "      <td>102</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[NEUTRAL]</td>\n",
       "      <td>[CONTEMPT]</td>\n",
       "      <td>0.006375</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.042205</td>\n",
       "      <td>0.006375</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.093554</td>\n",
       "      <td>0.112186</td>\n",
       "      <td>0.013172</td>\n",
       "      <td>2.448778e-04</td>\n",
       "      <td>S0</td>\n",
       "      <td>6.582</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>SUB103</td>\n",
       "      <td>SUB103_102_None</td>\n",
       "      <td>225</td>\n",
       "      <td>102</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[NEUTRAL]</td>\n",
       "      <td>[SADNESS]</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.031623</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.072298</td>\n",
       "      <td>0.086766</td>\n",
       "      <td>0.007557</td>\n",
       "      <td>9.750467e-05</td>\n",
       "      <td>S0</td>\n",
       "      <td>6.582</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>SUB103</td>\n",
       "      <td>SUB103_102_None</td>\n",
       "      <td>120</td>\n",
       "      <td>102</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[NEUTRAL]</td>\n",
       "      <td>[SADNESS]</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.022361</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.052732</td>\n",
       "      <td>0.063309</td>\n",
       "      <td>0.004016</td>\n",
       "      <td>3.192657e-05</td>\n",
       "      <td>S0</td>\n",
       "      <td>6.582</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>SUB103</td>\n",
       "      <td>SUB103_102_None</td>\n",
       "      <td>210</td>\n",
       "      <td>102</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.993</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[NEUTRAL]</td>\n",
       "      <td>[SADNESS]</td>\n",
       "      <td>0.001625</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.020156</td>\n",
       "      <td>0.001625</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.045673</td>\n",
       "      <td>0.054828</td>\n",
       "      <td>0.003512</td>\n",
       "      <td>1.791256e-05</td>\n",
       "      <td>S0</td>\n",
       "      <td>6.582</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256975</td>\n",
       "      <td>SUB997</td>\n",
       "      <td>SUB997_None_9594</td>\n",
       "      <td>45</td>\n",
       "      <td>None</td>\n",
       "      <td>9594</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[NEUTRAL]</td>\n",
       "      <td>[HAPPINESS, SADNESS]</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.019365</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.037260</td>\n",
       "      <td>0.044744</td>\n",
       "      <td>0.002004</td>\n",
       "      <td>3.295350e-06</td>\n",
       "      <td>P0</td>\n",
       "      <td>5.052</td>\n",
       "      <td>6.08</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256976</td>\n",
       "      <td>SUB997</td>\n",
       "      <td>SUB997_None_9594</td>\n",
       "      <td>150</td>\n",
       "      <td>None</td>\n",
       "      <td>9594</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[NEUTRAL]</td>\n",
       "      <td>[CONTEMPT, HAPPINESS, SADNESS]</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.019365</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.032262</td>\n",
       "      <td>0.038744</td>\n",
       "      <td>0.001502</td>\n",
       "      <td>9.863423e-07</td>\n",
       "      <td>P0</td>\n",
       "      <td>5.052</td>\n",
       "      <td>6.08</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256977</td>\n",
       "      <td>SUB997</td>\n",
       "      <td>SUB997_None_9594</td>\n",
       "      <td>225</td>\n",
       "      <td>None</td>\n",
       "      <td>9594</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[NEUTRAL]</td>\n",
       "      <td>[HAPPINESS]</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.015811</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.032262</td>\n",
       "      <td>0.038744</td>\n",
       "      <td>0.001502</td>\n",
       "      <td>2.137071e-06</td>\n",
       "      <td>P0</td>\n",
       "      <td>5.052</td>\n",
       "      <td>6.08</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256978</td>\n",
       "      <td>SUB997</td>\n",
       "      <td>SUB997_None_9594</td>\n",
       "      <td>270</td>\n",
       "      <td>None</td>\n",
       "      <td>9594</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[NEUTRAL]</td>\n",
       "      <td>[HAPPINESS]</td>\n",
       "      <td>0.000875</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.020156</td>\n",
       "      <td>0.000875</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.037241</td>\n",
       "      <td>0.044734</td>\n",
       "      <td>0.001502</td>\n",
       "      <td>2.137684e-06</td>\n",
       "      <td>P0</td>\n",
       "      <td>5.052</td>\n",
       "      <td>6.08</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256979</td>\n",
       "      <td>SUB997</td>\n",
       "      <td>SUB997_None_9594</td>\n",
       "      <td>345</td>\n",
       "      <td>None</td>\n",
       "      <td>9594</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[NEUTRAL]</td>\n",
       "      <td>[CONTEMPT, HAPPINESS, SADNESS]</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.019365</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.032262</td>\n",
       "      <td>0.038744</td>\n",
       "      <td>0.001502</td>\n",
       "      <td>9.863423e-07</td>\n",
       "      <td>P0</td>\n",
       "      <td>5.052</td>\n",
       "      <td>6.08</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>256980 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SUB_NAME           STIMULI  FRAME_NUMBER IADS_ID IAPS_ID  ANGER  \\\n",
       "0        SUB103   SUB103_102_None           300     102    None  0.001   \n",
       "1        SUB103   SUB103_102_None           195     102    None  0.000   \n",
       "2        SUB103   SUB103_102_None           225     102    None  0.000   \n",
       "3        SUB103   SUB103_102_None           120     102    None  0.000   \n",
       "4        SUB103   SUB103_102_None           210     102    None  0.000   \n",
       "...         ...               ...           ...     ...     ...    ...   \n",
       "256975   SUB997  SUB997_None_9594            45    None    9594  0.000   \n",
       "256976   SUB997  SUB997_None_9594           150    None    9594  0.000   \n",
       "256977   SUB997  SUB997_None_9594           225    None    9594  0.000   \n",
       "256978   SUB997  SUB997_None_9594           270    None    9594  0.000   \n",
       "256979   SUB997  SUB997_None_9594           345    None    9594  0.000   \n",
       "\n",
       "        CONTEMPT  DISGUST  FEAR  HAPPINESS  NEUTRAL  SADNESS  SURPRISE  \\\n",
       "0          0.207      0.0   0.0      0.000    0.789    0.003       0.0   \n",
       "1          0.022      0.0   0.0      0.000    0.974    0.003       0.0   \n",
       "2          0.001      0.0   0.0      0.000    0.985    0.014       0.0   \n",
       "3          0.000      0.0   0.0      0.000    0.992    0.008       0.0   \n",
       "4          0.000      0.0   0.0      0.000    0.993    0.006       0.0   \n",
       "...          ...      ...   ...        ...      ...      ...       ...   \n",
       "256975     0.000      0.0   0.0      0.002    0.996    0.002       0.0   \n",
       "256976     0.001      0.0   0.0      0.001    0.997    0.001       0.0   \n",
       "256977     0.001      0.0   0.0      0.002    0.997    0.000       0.0   \n",
       "256978     0.001      0.0   0.0      0.002    0.997    0.001       0.0   \n",
       "256979     0.001      0.0   0.0      0.001    0.997    0.001       0.0   \n",
       "\n",
       "        FIRST_EMO                         SEC_EMO  MEAN_ABS_ERR  MEAN_SQ_ERR  \\\n",
       "0       [NEUTRAL]                      [CONTEMPT]      0.052750     0.010922   \n",
       "1       [NEUTRAL]                      [CONTEMPT]      0.006375     0.000146   \n",
       "2       [NEUTRAL]                       [SADNESS]      0.003750     0.000053   \n",
       "3       [NEUTRAL]                       [SADNESS]      0.002000     0.000016   \n",
       "4       [NEUTRAL]                       [SADNESS]      0.001625     0.000011   \n",
       "...           ...                             ...           ...          ...   \n",
       "256975  [NEUTRAL]            [HAPPINESS, SADNESS]      0.001000     0.000003   \n",
       "256976  [NEUTRAL]  [CONTEMPT, HAPPINESS, SADNESS]      0.000750     0.000002   \n",
       "256977  [NEUTRAL]                     [HAPPINESS]      0.000750     0.000002   \n",
       "256978  [NEUTRAL]                     [HAPPINESS]      0.000875     0.000002   \n",
       "256979  [NEUTRAL]  [CONTEMPT, HAPPINESS, SADNESS]      0.000750     0.000002   \n",
       "\n",
       "          ENERGY  WASSERSTEIN  RELATIVE_ENTROPY  JENSENSHANNON  HELLINGER  \\\n",
       "0       0.116190     0.052750               inf       0.281714   0.334280   \n",
       "1       0.042205     0.006375               inf       0.093554   0.112186   \n",
       "2       0.031623     0.003750               inf       0.072298   0.086766   \n",
       "3       0.022361     0.002000               inf       0.052732   0.063309   \n",
       "4       0.020156     0.001625               inf       0.045673   0.054828   \n",
       "...          ...          ...               ...            ...        ...   \n",
       "256975  0.019365     0.001000               inf       0.037260   0.044744   \n",
       "256976  0.019365     0.000750               inf       0.032262   0.038744   \n",
       "256977  0.015811     0.000750               inf       0.032262   0.038744   \n",
       "256978  0.020156     0.000875               inf       0.037241   0.044734   \n",
       "256979  0.019365     0.000750               inf       0.032262   0.038744   \n",
       "\n",
       "        BHATTACHARYYA_DIST   CORRELATION COND  ANS_VALENCE  ANS_AROUSAL  \\\n",
       "0                 0.118494  3.436184e-02   S0        6.582         5.00   \n",
       "1                 0.013172  2.448778e-04   S0        6.582         5.00   \n",
       "2                 0.007557  9.750467e-05   S0        6.582         5.00   \n",
       "3                 0.004016  3.192657e-05   S0        6.582         5.00   \n",
       "4                 0.003512  1.791256e-05   S0        6.582         5.00   \n",
       "...                    ...           ...  ...          ...          ...   \n",
       "256975            0.002004  3.295350e-06   P0        5.052         6.08   \n",
       "256976            0.001502  9.863423e-07   P0        5.052         6.08   \n",
       "256977            0.001502  2.137071e-06   P0        5.052         6.08   \n",
       "256978            0.001502  2.137684e-06   P0        5.052         6.08   \n",
       "256979            0.001502  9.863423e-07   P0        5.052         6.08   \n",
       "\n",
       "        OPENNESS  CONSCIENTIOUSNESS  NEUROTICISM  AGREEABLENESS  EXTRAVERSION  \n",
       "0              6                  6            2              3             4  \n",
       "1              6                  6            2              3             4  \n",
       "2              6                  6            2              3             4  \n",
       "3              6                  6            2              3             4  \n",
       "4              6                  6            2              3             4  \n",
       "...          ...                ...          ...            ...           ...  \n",
       "256975         1                  3            7              4             1  \n",
       "256976         1                  3            7              4             1  \n",
       "256977         1                  3            7              4             1  \n",
       "256978         1                  3            7              4             1  \n",
       "256979         1                  3            7              4             1  \n",
       "\n",
       "[256980 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.drop('RELATIVE_ENTROPY',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## take only least neutral row from each stimuli\n",
    "#### This is ordered dataset; by stimuli and neutral emotion asc so I can grab it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_only_df=df_full.groupby('STIMULI').first().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, shuffle it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_only_df = first_only_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STIMULI</th>\n",
       "      <th>SUB_NAME</th>\n",
       "      <th>FRAME_NUMBER</th>\n",
       "      <th>IADS_ID</th>\n",
       "      <th>IAPS_ID</th>\n",
       "      <th>ANGER</th>\n",
       "      <th>CONTEMPT</th>\n",
       "      <th>DISGUST</th>\n",
       "      <th>FEAR</th>\n",
       "      <th>HAPPINESS</th>\n",
       "      <th>NEUTRAL</th>\n",
       "      <th>SADNESS</th>\n",
       "      <th>SURPRISE</th>\n",
       "      <th>FIRST_EMO</th>\n",
       "      <th>SEC_EMO</th>\n",
       "      <th>MEAN_ABS_ERR</th>\n",
       "      <th>MEAN_SQ_ERR</th>\n",
       "      <th>ENERGY</th>\n",
       "      <th>WASSERSTEIN</th>\n",
       "      <th>JENSENSHANNON</th>\n",
       "      <th>HELLINGER</th>\n",
       "      <th>BHATTACHARYYA_DIST</th>\n",
       "      <th>CORRELATION</th>\n",
       "      <th>COND</th>\n",
       "      <th>ANS_VALENCE</th>\n",
       "      <th>ANS_AROUSAL</th>\n",
       "      <th>OPENNESS</th>\n",
       "      <th>CONSCIENTIOUSNESS</th>\n",
       "      <th>NEUROTICISM</th>\n",
       "      <th>AGREEABLENESS</th>\n",
       "      <th>EXTRAVERSION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>SUB383_244_2811</td>\n",
       "      <td>SUB383</td>\n",
       "      <td>240</td>\n",
       "      <td>244</td>\n",
       "      <td>2811</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[NEUTRAL]</td>\n",
       "      <td>[SADNESS]</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>6.250000e-07</td>\n",
       "      <td>0.009682</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.018629</td>\n",
       "      <td>0.022372</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>4.919014e-07</td>\n",
       "      <td>PS-</td>\n",
       "      <td>2.602</td>\n",
       "      <td>6.307</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>SUB465_None_6610</td>\n",
       "      <td>SUB465</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>6610</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[NEUTRAL]</td>\n",
       "      <td>[CONTEMPT]</td>\n",
       "      <td>0.009125</td>\n",
       "      <td>2.528750e-04</td>\n",
       "      <td>0.056734</td>\n",
       "      <td>0.009125</td>\n",
       "      <td>0.112492</td>\n",
       "      <td>0.134811</td>\n",
       "      <td>0.018851</td>\n",
       "      <td>2.918844e-04</td>\n",
       "      <td>P0</td>\n",
       "      <td>3.599</td>\n",
       "      <td>2.894</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>SUB829_None_1945</td>\n",
       "      <td>SUB829</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>1945</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[NEUTRAL]</td>\n",
       "      <td>[SADNESS]</td>\n",
       "      <td>0.012250</td>\n",
       "      <td>5.882500e-04</td>\n",
       "      <td>0.055902</td>\n",
       "      <td>0.012250</td>\n",
       "      <td>0.131491</td>\n",
       "      <td>0.157505</td>\n",
       "      <td>0.025121</td>\n",
       "      <td>1.255736e-03</td>\n",
       "      <td>P0</td>\n",
       "      <td>3.120</td>\n",
       "      <td>3.725</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>SUB959_808_7230</td>\n",
       "      <td>SUB959</td>\n",
       "      <td>180</td>\n",
       "      <td>808</td>\n",
       "      <td>7230</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[NEUTRAL]</td>\n",
       "      <td>[ANGER, CONTEMPT, DISGUST, FEAR, HAPPINESS, SA...</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>1.250000e-07</td>\n",
       "      <td>0.005590</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>PS+</td>\n",
       "      <td>4.132</td>\n",
       "      <td>5.698</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>SUB208_713_3140</td>\n",
       "      <td>SUB208</td>\n",
       "      <td>30</td>\n",
       "      <td>713</td>\n",
       "      <td>3140</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[NEUTRAL]</td>\n",
       "      <td>[SADNESS]</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>1.690000e-04</td>\n",
       "      <td>0.040311</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>0.095376</td>\n",
       "      <td>0.114392</td>\n",
       "      <td>0.013172</td>\n",
       "      <td>3.515067e-04</td>\n",
       "      <td>PS-</td>\n",
       "      <td>2.216</td>\n",
       "      <td>7.059</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11012</td>\n",
       "      <td>SUB267_365_8206</td>\n",
       "      <td>SUB267</td>\n",
       "      <td>195</td>\n",
       "      <td>365</td>\n",
       "      <td>8206</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[NEUTRAL]</td>\n",
       "      <td>[CONTEMPT]</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>9.000000e-06</td>\n",
       "      <td>0.019365</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.045650</td>\n",
       "      <td>0.054813</td>\n",
       "      <td>0.003009</td>\n",
       "      <td>1.787650e-05</td>\n",
       "      <td>PS+</td>\n",
       "      <td>4.568</td>\n",
       "      <td>3.596</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11013</td>\n",
       "      <td>SUB333_None_7484</td>\n",
       "      <td>SUB333</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>7484</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.08</td>\n",
       "      <td>[NEUTRAL]</td>\n",
       "      <td>[FEAR]</td>\n",
       "      <td>0.043750</td>\n",
       "      <td>5.504500e-03</td>\n",
       "      <td>0.132288</td>\n",
       "      <td>0.043750</td>\n",
       "      <td>0.254661</td>\n",
       "      <td>0.302828</td>\n",
       "      <td>0.096186</td>\n",
       "      <td>7.971516e-03</td>\n",
       "      <td>P0</td>\n",
       "      <td>4.029</td>\n",
       "      <td>2.819</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11014</td>\n",
       "      <td>SUB211_290_None</td>\n",
       "      <td>SUB211</td>\n",
       "      <td>330</td>\n",
       "      <td>290</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[NEUTRAL]</td>\n",
       "      <td>[SADNESS]</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>3.570250e-03</td>\n",
       "      <td>0.086963</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.208579</td>\n",
       "      <td>0.248831</td>\n",
       "      <td>0.063917</td>\n",
       "      <td>9.163101e-03</td>\n",
       "      <td>S-</td>\n",
       "      <td>1.000</td>\n",
       "      <td>8.438</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11015</td>\n",
       "      <td>SUB200_378_5626</td>\n",
       "      <td>SUB200</td>\n",
       "      <td>180</td>\n",
       "      <td>378</td>\n",
       "      <td>5626</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[NEUTRAL]</td>\n",
       "      <td>[SADNESS]</td>\n",
       "      <td>0.047625</td>\n",
       "      <td>9.072625e-03</td>\n",
       "      <td>0.109116</td>\n",
       "      <td>0.047625</td>\n",
       "      <td>0.266310</td>\n",
       "      <td>0.316316</td>\n",
       "      <td>0.105978</td>\n",
       "      <td>2.772725e-02</td>\n",
       "      <td>PS+</td>\n",
       "      <td>6.552</td>\n",
       "      <td>6.110</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11016</td>\n",
       "      <td>SUB683_813_7502</td>\n",
       "      <td>SUB683</td>\n",
       "      <td>255</td>\n",
       "      <td>813</td>\n",
       "      <td>7502</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[NEUTRAL]</td>\n",
       "      <td>[SADNESS]</td>\n",
       "      <td>0.023750</td>\n",
       "      <td>2.256500e-03</td>\n",
       "      <td>0.077055</td>\n",
       "      <td>0.023750</td>\n",
       "      <td>0.183868</td>\n",
       "      <td>0.219570</td>\n",
       "      <td>0.050463</td>\n",
       "      <td>5.412479e-03</td>\n",
       "      <td>PS+</td>\n",
       "      <td>7.836</td>\n",
       "      <td>3.167</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11017 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                STIMULI SUB_NAME  FRAME_NUMBER IADS_ID IAPS_ID  ANGER  \\\n",
       "0       SUB383_244_2811   SUB383           240     244    2811  0.000   \n",
       "1      SUB465_None_6610   SUB465             0    None    6610  0.013   \n",
       "2      SUB829_None_1945   SUB829             0    None    1945  0.000   \n",
       "3       SUB959_808_7230   SUB959           180     808    7230  0.000   \n",
       "4       SUB208_713_3140   SUB208            30     713    3140  0.000   \n",
       "...                 ...      ...           ...     ...     ...    ...   \n",
       "11012   SUB267_365_8206   SUB267           195     365    8206  0.000   \n",
       "11013  SUB333_None_7484   SUB333            15    None    7484  0.001   \n",
       "11014   SUB211_290_None   SUB211           330     290    None  0.000   \n",
       "11015   SUB200_378_5626   SUB200           180     378    5626  0.000   \n",
       "11016   SUB683_813_7502   SUB683           255     813    7502  0.000   \n",
       "\n",
       "       CONTEMPT  DISGUST   FEAR  HAPPINESS  NEUTRAL  SADNESS  SURPRISE  \\\n",
       "0         0.000      0.0  0.000        0.0    0.998    0.001      0.00   \n",
       "1         0.022      0.0  0.000        0.0    0.963    0.001      0.00   \n",
       "2         0.001      0.0  0.000        0.0    0.951    0.048      0.00   \n",
       "3         0.000      0.0  0.000        0.0    0.999    0.000      0.00   \n",
       "4         0.000      0.0  0.000        0.0    0.974    0.026      0.00   \n",
       "...         ...      ...    ...        ...      ...      ...       ...   \n",
       "11012     0.006      0.0  0.000        0.0    0.994    0.000      0.00   \n",
       "11013     0.000      0.0  0.083        0.0    0.825    0.011      0.08   \n",
       "11014     0.001      0.0  0.000        0.0    0.880    0.119      0.00   \n",
       "11015     0.000      0.0  0.000        0.0    0.809    0.190      0.00   \n",
       "11016     0.000      0.0  0.000        0.0    0.904    0.094      0.00   \n",
       "\n",
       "       FIRST_EMO                                            SEC_EMO  \\\n",
       "0      [NEUTRAL]                                          [SADNESS]   \n",
       "1      [NEUTRAL]                                         [CONTEMPT]   \n",
       "2      [NEUTRAL]                                          [SADNESS]   \n",
       "3      [NEUTRAL]  [ANGER, CONTEMPT, DISGUST, FEAR, HAPPINESS, SA...   \n",
       "4      [NEUTRAL]                                          [SADNESS]   \n",
       "...          ...                                                ...   \n",
       "11012  [NEUTRAL]                                         [CONTEMPT]   \n",
       "11013  [NEUTRAL]                                             [FEAR]   \n",
       "11014  [NEUTRAL]                                          [SADNESS]   \n",
       "11015  [NEUTRAL]                                          [SADNESS]   \n",
       "11016  [NEUTRAL]                                          [SADNESS]   \n",
       "\n",
       "       MEAN_ABS_ERR   MEAN_SQ_ERR    ENERGY  WASSERSTEIN  JENSENSHANNON  \\\n",
       "0          0.000375  6.250000e-07  0.009682     0.000375       0.018629   \n",
       "1          0.009125  2.528750e-04  0.056734     0.009125       0.112492   \n",
       "2          0.012250  5.882500e-04  0.055902     0.012250       0.131491   \n",
       "3          0.000125  1.250000e-07  0.005590     0.000125       0.000002   \n",
       "4          0.006500  1.690000e-04  0.040311     0.006500       0.095376   \n",
       "...             ...           ...       ...          ...            ...   \n",
       "11012      0.001500  9.000000e-06  0.019365     0.001500       0.045650   \n",
       "11013      0.043750  5.504500e-03  0.132288     0.043750       0.254661   \n",
       "11014      0.030000  3.570250e-03  0.086963     0.030000       0.208579   \n",
       "11015      0.047625  9.072625e-03  0.109116     0.047625       0.266310   \n",
       "11016      0.023750  2.256500e-03  0.077055     0.023750       0.183868   \n",
       "\n",
       "       HELLINGER  BHATTACHARYYA_DIST   CORRELATION COND  ANS_VALENCE  \\\n",
       "0       0.022372            0.001001  4.919014e-07  PS-        2.602   \n",
       "1       0.134811            0.018851  2.918844e-04   P0        3.599   \n",
       "2       0.157505            0.025121  1.255736e-03   P0        3.120   \n",
       "3       0.000354            0.000500  1.110223e-16  PS+        4.132   \n",
       "4       0.114392            0.013172  3.515067e-04  PS-        2.216   \n",
       "...          ...                 ...           ...  ...          ...   \n",
       "11012   0.054813            0.003009  1.787650e-05  PS+        4.568   \n",
       "11013   0.302828            0.096186  7.971516e-03   P0        4.029   \n",
       "11014   0.248831            0.063917  9.163101e-03   S-        1.000   \n",
       "11015   0.316316            0.105978  2.772725e-02  PS+        6.552   \n",
       "11016   0.219570            0.050463  5.412479e-03  PS+        7.836   \n",
       "\n",
       "       ANS_AROUSAL  OPENNESS  CONSCIENTIOUSNESS  NEUROTICISM  AGREEABLENESS  \\\n",
       "0            6.307         4                  8            7              8   \n",
       "1            2.894         7                  5            5              3   \n",
       "2            3.725         5                  9            6             10   \n",
       "3            5.698         8                  7            2              8   \n",
       "4            7.059         5                  4            7              6   \n",
       "...            ...       ...                ...          ...            ...   \n",
       "11012        3.596         6                  8            8              6   \n",
       "11013        2.819         7                  9            2              2   \n",
       "11014        8.438         5                 10            5              5   \n",
       "11015        6.110         3                  8            7              1   \n",
       "11016        3.167         8                  5            8              9   \n",
       "\n",
       "       EXTRAVERSION  \n",
       "0                 4  \n",
       "1                 6  \n",
       "2                 7  \n",
       "3                 4  \n",
       "4                 4  \n",
       "...             ...  \n",
       "11012             3  \n",
       "11013             3  \n",
       "11014             7  \n",
       "11015             2  \n",
       "11016             5  \n",
       "\n",
       "[11017 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_only_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define input and output for model testing\n",
    "\n",
    "Input to be tested:\n",
    "\n",
    "    1.emotion distribution only\n",
    "    2.emotion distribution + personality traits\n",
    "    3.chosen statistical distances + categorical data of first and second most recognized emotion + personality traits\n",
    "   \n",
    "Output to be tested (val/arousal):\n",
    "\n",
    "    1.continous --> regression problem\n",
    "    2.categorical --> classification problem: LOW,MODERATE,HIGH VxA (VALUES ARE 1-9 ORGINALLY)\n",
    "                                              or LOW,HIGH VxA\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "emo_only_df=first_only_df[['ANGER','CONTEMPT','DISGUST','FEAR','HAPPINESS','NEUTRAL','SADNESS','SURPRISE']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "emo_personality_df=first_only_df[['ANGER','CONTEMPT','DISGUST','FEAR','HAPPINESS','NEUTRAL','SADNESS','SURPRISE','OPENNESS','CONSCIENTIOUSNESS','NEUROTICISM','AGREEABLENESS','EXTRAVERSION']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### chosen stat distances: \n",
    "we could choose the useful ones based on its st dev and mean. the more deviation the more \"active\" the measure is and perhaps can yield best results\n",
    "also it would be good to exclude correlation effects between those we use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN_ABS_ERR std:  0.05871694138854942   mean:  0.047254527094490156\n",
      "MEAN_SQ_ERR std:  0.049869753702819715   mean:  0.021872283890805144\n",
      "ENERGY std:  0.048041340573577174   mean:  0.08339113610596843\n",
      "WASSERSTEIN std:  0.03412057343278713   mean:  0.03428191658346192\n",
      "JENSENSHANNON std:  0.17960019611312467   mean:  0.2332994236072252\n",
      "HELLINGER std:  0.20814392916338756   mean:  0.2751948796526792\n",
      "BHATTACHARYYA_DIST std:  0.7715897503421415   mean:  0.19184335772446023\n",
      "CORRELATION std:  0.25794473605979784   mean:  0.1071791640690879\n"
     ]
    }
   ],
   "source": [
    "distances_lst=['MEAN_ABS_ERR','MEAN_SQ_ERR','ENERGY','WASSERSTEIN','JENSENSHANNON','HELLINGER','BHATTACHARYYA_DIST','CORRELATION']\n",
    "#distances_lst=['MEAN_ABS_ERR']\n",
    "for dist in distances_lst:\n",
    "    dist_df=first_only_df[dist]\n",
    "    print(dist, 'std: ',dist_df.std(),'  mean: ',dist_df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pearson corr btween  MEAN_ABS_ERR and  MEAN_ABS_ERR is:  1.0\n",
      "pearson corr btween  MEAN_ABS_ERR and  MEAN_SQ_ERR is:  0.9382144692559544\n",
      "pearson corr btween  MEAN_ABS_ERR and  ENERGY is:  0.5456154538048086\n",
      "pearson corr btween  MEAN_ABS_ERR and  WASSERSTEIN is:  0.5848687965958042\n",
      "pearson corr btween  MEAN_ABS_ERR and  JENSENSHANNON is:  0.9873156461250121\n",
      "pearson corr btween  MEAN_ABS_ERR and  HELLINGER is:  0.9850048792383163\n",
      "pearson corr btween  MEAN_ABS_ERR and  BHATTACHARYYA_DIST is:  0.5255459362234071\n",
      "pearson corr btween  MEAN_ABS_ERR and  CORRELATION is:  0.9379683098335648\n",
      "##############\n",
      "pearson corr btween  MEAN_SQ_ERR and  MEAN_ABS_ERR is:  0.9382144692559544\n",
      "pearson corr btween  MEAN_SQ_ERR and  MEAN_SQ_ERR is:  0.9999999999999999\n",
      "pearson corr btween  MEAN_SQ_ERR and  ENERGY is:  0.22647555649781329\n",
      "pearson corr btween  MEAN_SQ_ERR and  WASSERSTEIN is:  0.2771717395465839\n",
      "pearson corr btween  MEAN_SQ_ERR and  JENSENSHANNON is:  0.8923657908319991\n",
      "pearson corr btween  MEAN_SQ_ERR and  HELLINGER is:  0.8894294222982126\n",
      "pearson corr btween  MEAN_SQ_ERR and  BHATTACHARYYA_DIST is:  0.5804440798369942\n",
      "pearson corr btween  MEAN_SQ_ERR and  CORRELATION is:  0.9909787097024937\n",
      "##############\n",
      "pearson corr btween  ENERGY and  MEAN_ABS_ERR is:  0.5456154538048087\n",
      "pearson corr btween  ENERGY and  MEAN_SQ_ERR is:  0.22647555649781326\n",
      "pearson corr btween  ENERGY and  ENERGY is:  0.9999999999999999\n",
      "pearson corr btween  ENERGY and  WASSERSTEIN is:  0.9643390696854344\n",
      "pearson corr btween  ENERGY and  JENSENSHANNON is:  0.6250521519591351\n",
      "pearson corr btween  ENERGY and  HELLINGER is:  0.6251636389257779\n",
      "pearson corr btween  ENERGY and  BHATTACHARYYA_DIST is:  0.08345205849698123\n",
      "pearson corr btween  ENERGY and  CORRELATION is:  0.25096575666885357\n",
      "##############\n",
      "pearson corr btween  WASSERSTEIN and  MEAN_ABS_ERR is:  0.5848687965958042\n",
      "pearson corr btween  WASSERSTEIN and  MEAN_SQ_ERR is:  0.2771717395465839\n",
      "pearson corr btween  WASSERSTEIN and  ENERGY is:  0.9643390696854345\n",
      "pearson corr btween  WASSERSTEIN and  WASSERSTEIN is:  0.9999999999999998\n",
      "pearson corr btween  WASSERSTEIN and  JENSENSHANNON is:  0.6386932749530683\n",
      "pearson corr btween  WASSERSTEIN and  HELLINGER is:  0.6381897780839502\n",
      "pearson corr btween  WASSERSTEIN and  BHATTACHARYYA_DIST is:  0.10130601176968305\n",
      "pearson corr btween  WASSERSTEIN and  CORRELATION is:  0.30234667225404155\n",
      "##############\n",
      "pearson corr btween  JENSENSHANNON and  MEAN_ABS_ERR is:  0.9873156461250122\n",
      "pearson corr btween  JENSENSHANNON and  MEAN_SQ_ERR is:  0.8923657908319991\n",
      "pearson corr btween  JENSENSHANNON and  ENERGY is:  0.625052151959135\n",
      "pearson corr btween  JENSENSHANNON and  WASSERSTEIN is:  0.6386932749530683\n",
      "pearson corr btween  JENSENSHANNON and  JENSENSHANNON is:  0.9999999999999999\n",
      "pearson corr btween  JENSENSHANNON and  HELLINGER is:  0.9997373929062479\n",
      "pearson corr btween  JENSENSHANNON and  BHATTACHARYYA_DIST is:  0.5055348018131194\n",
      "pearson corr btween  JENSENSHANNON and  CORRELATION is:  0.8856020081929893\n",
      "##############\n",
      "pearson corr btween  HELLINGER and  MEAN_ABS_ERR is:  0.9850048792383163\n",
      "pearson corr btween  HELLINGER and  MEAN_SQ_ERR is:  0.8894294222982125\n",
      "pearson corr btween  HELLINGER and  ENERGY is:  0.6251636389257778\n",
      "pearson corr btween  HELLINGER and  WASSERSTEIN is:  0.6381897780839502\n",
      "pearson corr btween  HELLINGER and  JENSENSHANNON is:  0.9997373929062479\n",
      "pearson corr btween  HELLINGER and  HELLINGER is:  0.9999999999999999\n",
      "pearson corr btween  HELLINGER and  BHATTACHARYYA_DIST is:  0.509402871960714\n",
      "pearson corr btween  HELLINGER and  CORRELATION is:  0.8808419799193516\n",
      "##############\n",
      "pearson corr btween  BHATTACHARYYA_DIST and  MEAN_ABS_ERR is:  0.5255459362234071\n",
      "pearson corr btween  BHATTACHARYYA_DIST and  MEAN_SQ_ERR is:  0.5804440798369942\n",
      "pearson corr btween  BHATTACHARYYA_DIST and  ENERGY is:  0.08345205849698123\n",
      "pearson corr btween  BHATTACHARYYA_DIST and  WASSERSTEIN is:  0.10130601176968304\n",
      "pearson corr btween  BHATTACHARYYA_DIST and  JENSENSHANNON is:  0.5055348018131194\n",
      "pearson corr btween  BHATTACHARYYA_DIST and  HELLINGER is:  0.5094028719607139\n",
      "pearson corr btween  BHATTACHARYYA_DIST and  BHATTACHARYYA_DIST is:  1.0\n",
      "pearson corr btween  BHATTACHARYYA_DIST and  CORRELATION is:  0.5723333014123433\n",
      "##############\n",
      "pearson corr btween  CORRELATION and  MEAN_ABS_ERR is:  0.9379683098335648\n",
      "pearson corr btween  CORRELATION and  MEAN_SQ_ERR is:  0.9909787097024936\n",
      "pearson corr btween  CORRELATION and  ENERGY is:  0.2509657566688536\n",
      "pearson corr btween  CORRELATION and  WASSERSTEIN is:  0.30234667225404155\n",
      "pearson corr btween  CORRELATION and  JENSENSHANNON is:  0.8856020081929894\n",
      "pearson corr btween  CORRELATION and  HELLINGER is:  0.8808419799193516\n",
      "pearson corr btween  CORRELATION and  BHATTACHARYYA_DIST is:  0.5723333014123434\n",
      "pearson corr btween  CORRELATION and  CORRELATION is:  1.0\n",
      "##############\n"
     ]
    }
   ],
   "source": [
    "#first_only_df['BHATTACHARYYA_DIST'].corr(first_only_df['HELLINGER'])\n",
    "for dist_1 in distances_lst:\n",
    "    dist_1_df=first_only_df[dist_1]\n",
    "    for dist_2 in distances_lst:\n",
    "        dist_2_df=first_only_df[dist_2]\n",
    "        print('pearson corr btween ', dist_1,'and ', dist_2, 'is: ', dist_1_df.corr(dist_2_df))\n",
    "    print('##############')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will go with BHATTACHARYYA_DIST and HELLINGER: 0.5 correlation (moderate) and and highest std  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_df=first_only_df[['BHATTACHARYYA_DIST','HELLINGER']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hot-one encode first and second highest recognized emotion labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "hot_one_f=pd.DataFrame(mlb.fit_transform(first_only_df.FIRST_EMO),columns=mlb.classes_, index=first_only_df.index)\n",
    "hot_one_s=pd.DataFrame(mlb.fit_transform(first_only_df.SEC_EMO),columns=mlb.classes_, index=first_only_df.index)\n",
    "\n",
    "hot_one_f.rename({    \n",
    "    'ANGER':'ANGER_F',\n",
    "    'CONTEMPT':'CONTEMPT_F',\n",
    "    'DISGUST':'DISGUST_F',\n",
    "    'FEAR':'FEAR_F',\n",
    "    'HAPPINESS':'HAPPINESS_F',\n",
    "    'NEUTRAL':'NEUTRAL_F',\n",
    "    'SADNESS':'SADNESS_F',    \n",
    "    }, axis=1, inplace=True)\n",
    "\n",
    "hot_one_s.rename({    \n",
    "    'ANGER':'ANGER_S',\n",
    "    'CONTEMPT':'CONTEMPT_S',\n",
    "    'DISGUST':'DISGUST_S',\n",
    "    'FEAR':'FEAR_S',\n",
    "    'HAPPINESS':'HAPPINESS_S',\n",
    "    'NEUTRAL':'NEUTRAL_S',\n",
    "    'SADNESS':'SADNESS_S',    \n",
    "    }, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "hot_one_both=pd.merge(hot_one_f, hot_one_s, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "personality_df=first_only_df[['OPENNESS','CONSCIENTIOUSNESS','NEUROTICISM','AGREEABLENESS','EXTRAVERSION']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_cat_pers_df=pd.merge(dist_df, hot_one_both, left_index=True, right_index=True)\n",
    "stat_cat_pers_df=pd.merge(stat_cat_pers_df, personality_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df=first_only_df[['ANS_VALENCE','ANS_AROUSAL']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bartk\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\bartk\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\bartk\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\bartk\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "def to_cat(val):\n",
    "    if val >=1 and val <3:\n",
    "        return 'LOW'\n",
    "    elif val >=3 and val <6:\n",
    "        return 'MODERATE'\n",
    "    elif val >=6 and val <=9:\n",
    "        return 'HIGH'\n",
    "def to_cat2(val):\n",
    "    if val >=1 and val <5:\n",
    "        return 'LOW'\n",
    "    elif val >=5 and val <=9:\n",
    "        return 'HIGH'\n",
    "    \n",
    "def to_num(key):\n",
    "    classes={\n",
    "    'LOW VALENCE LOW AROUSAL':0,\n",
    "    'LOW VALENCE MODERATE AROUSAL':1,\n",
    "    'LOW VALENCE HIGH AROUSAL':2,\n",
    "    'MODERATE VALENCE LOW AROUSAL':3,\n",
    "    'MODERATE VALENCE MODERATE AROUSAL':4,\n",
    "    'MODERATE VALENCE HIGH AROUSAL':5,\n",
    "    'HIGH VALENCE LOW AROUSAL':6,\n",
    "    'HIGH VALENCE MODERATE AROUSAL':7,\n",
    "    'HIGH VALENCE HIGH AROUSAL':8,\n",
    "    }\n",
    "    return classes.get(key)\n",
    "\n",
    "def to_num2(key):\n",
    "    classes={\n",
    "    'LOW VALENCE LOW AROUSAL':0,\n",
    "    'LOW VALENCE HIGH AROUSAL':1,\n",
    "    'HIGH VALENCE LOW AROUSAL':2,\n",
    "    'HIGH VALENCE HIGH AROUSAL':3,\n",
    "    }\n",
    "    return classes.get(key)\n",
    "\n",
    "y_df['AROUSAL_VAL_CAT'] = y_df.apply(lambda row: to_cat(row['ANS_VALENCE']) +' VALENCE '+ to_cat(row['ANS_AROUSAL']) + ' AROUSAL' , axis=1)\n",
    "y_df['VAL_AR_NUM']=y_df.apply(lambda row: to_num(row['AROUSAL_VAL_CAT']), axis=1)\n",
    "\n",
    "y_df['AROUSAL_VAL_CAT2'] = y_df.apply(lambda row: to_cat2(row['ANS_VALENCE']) +' VALENCE '+ to_cat2(row['ANS_AROUSAL']) + ' AROUSAL' , axis=1)\n",
    "y_df['VAL_AR_NUM2']=y_df.apply(lambda row: to_num2(row['AROUSAL_VAL_CAT2']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_lst=[\n",
    "    (emo_only_df,'emotion only'),\n",
    "    (emo_personality_df, 'emotion + personality'),\n",
    "    (stat_cat_pers_df, 'stat distanes + emotion labels')\n",
    "]\n",
    "\n",
    "input_lst_transform=[]\n",
    "for X,name in input_lst:\n",
    "    X=X.to_numpy()\n",
    "    scaler=StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X=scaler.transform(X)\n",
    "    res=(X,name)\n",
    "    input_lst_transform.append(res)\n",
    "    \n",
    "    \n",
    "y=y_df[['ANS_VALENCE','ANS_AROUSAL']].to_numpy()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units=[5,10,15,20,30,40,50]\n",
    "activations_last_layer=['linear','relu']\n",
    "epochs=[20,40]\n",
    "y=y_df[['ANS_VALENCE','ANS_AROUSAL']].to_numpy()\n",
    "\n",
    "def NN_regression(n_inputs, n_outputs,unit,activation):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(unit, input_dim=n_inputs, kernel_initializer='he_uniform', activation='relu'))\n",
    "    model.add(Dense(n_outputs,activation=activation))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam',metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "with open('ModelsResults.txt', 'w') as file:\n",
    "            file.write('Regression Approach:\\nNEURAL NETWORK- 2 dense layers (input and output)'.format(input_[1]))\n",
    "\n",
    "for input_ in input_lst_transform:\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(input_[0], y, test_size = 0.2, random_state = 42)\n",
    "    with open('ModelsResults.txt', 'a') as file:\n",
    "                file.write('\\n Input used: {}'.format(input_[1]))\n",
    "    for unit in units:\n",
    "        for activation in activations_last_layer:\n",
    "            for epoch_n in epochs:\n",
    "                model=NN_regression(X_train.shape[1], y_train.shape[1],unit,activation)\n",
    "                history = model.fit(X_train, y_train, validation_split=0.2, epochs =epoch_n,verbose=0)\n",
    "                mse_neural, mae_neural = model.evaluate(X_test, y_test)\n",
    "                with open('ModelsResults.txt', 'a') as file:\n",
    "                    file.write(\"\"\"\\n\\n\\t Configuration: {} units, {} activation function on output layer, {} epochs\n",
    "                                   \\n\\t\\t Mean squared error from neural net: {}\n",
    "                                   \\n\\t\\t Mean absolute error from neural net: {}\"\"\".format(unit,activation,\n",
    "                                                                                            epoch_n,mse_neural,mae_neural))\n",
    "#     print('Mean squared error from neural net: ', mse_neural)\n",
    "#     print('Mean absolute error from neural net: ', mae_neural)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc = history.history['mae']\n",
    "# val_acc = history.history['val_mae']\n",
    "# plt.plot(epochs, acc, 'y', label='Training MAE')\n",
    "# plt.plot(epochs, val_acc, 'r', label='Validation MAE')\n",
    "# plt.title('Training and validation MAE')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('MAE')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction: \n",
    "# predictions = model.predict(X_test[15:20:])\n",
    "# print(\"Predicted values are:\\n\\n\", predictions)\n",
    "# print(\"\\nReal values are:\\n\\n\", y_test[15:20:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random  Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find good parameters by randomly choosing combination of parameters. Save the best ones and write an estimation to txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 500, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 10)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "best_random_lst=[]\n",
    "for input_ in input_lst_transform:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(input_[0], y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "    rf = RandomForestRegressor()\n",
    "    rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 5, \n",
    "                                   verbose=1, random_state=42, n_jobs = -1)\n",
    "    rf_random.fit(X_train, y_train)\n",
    "    res=(input_[1],rf_random.best_estimator_)\n",
    "    best_random_lst.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('RandomForestRegression.txt', 'w') as file:\n",
    "    file.write(\"RandomForestRegression\")\n",
    "\n",
    "\n",
    "for name, model in best_random_lst:\n",
    "    with open('RandomForestRegression.txt', 'a') as file:\n",
    "        file.write(\"\\n\\nInput data used: {}\\nmodel parameters used: {}\\n\\n\".format(name,model))\n",
    "    \n",
    "    for data,ds_name in input_lst_transform:\n",
    "        if ds_name == name:\n",
    "            X = data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_RF = model.predict(X_test)\n",
    "    mse_RF = mean_squared_error(y_test, y_pred_RF)\n",
    "    mae_RF = mean_absolute_error(y_test, y_pred_RF)\n",
    "    with open('RandomForestRegression.txt', 'a') as file:\n",
    "        file.write(\"Results\\n\\t'Mean squared error using Random Forest: {}'\\n\\t'Mean absolute error using Random Forest: {}\".format(mse_RF,mae_RF))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xd = MultiOutputRegressor(SVR())\n",
    "xd.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try out how different kernels and C, gamma values affect the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining parameter range\n",
    "param_grid = {'estimator__C': [0.1, 1, 10, 100, 1000], \n",
    "              'estimator__gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'estimator__kernel': ['linear','rbf','sigmoid']} \n",
    "\n",
    "best_estimator_lst = []\n",
    "for input_ in input_lst_transform:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(input_[0], y, test_size = 0.2, random_state = 42)\n",
    "    grid = GridSearchCV(MultiOutputRegressor(SVR()), param_grid, cv=5, verbose = 3,n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    res=(input_[1],grid.best_estimator_)\n",
    "    best_estimator_lst.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SupportVectorRegression.txt', 'w') as file:\n",
    "    file.write(\"SupportVectorRegression\")\n",
    "\n",
    "\n",
    "for name, model in best_estimator_lst:\n",
    "    with open('SupportVectorRegression.txt', 'a') as file:\n",
    "        file.write(\"\\n\\nInput data used: {}\\nmodel parameters used: {}\\n\\n\".format(name,model))\n",
    "    \n",
    "    for data,ds_name in input_lst_transform:\n",
    "        if ds_name == name:\n",
    "            X = data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "        \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_SVR = model.predict(X_test)\n",
    "    mse_SVR = mean_squared_error(y_test, y_pred_SVR)\n",
    "    mae_SVR = mean_absolute_error(y_test, y_pred_SVR)\n",
    "    with open('SupportVectorRegression.txt', 'a') as file:\n",
    "        file.write(\"Results\\n\\t'Mean squared error using SVR: {}'\\n\\t'Mean absolute error using SVR: {}\".format(mse_SVR,mae_SVR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFICATION APPROACH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 CATEGORIES\n",
      "AROUSAL_VAL_CAT\n",
      "LOW VALENCE LOW AROUSAL               289\n",
      "HIGH VALENCE LOW AROUSAL              372\n",
      "MODERATE VALENCE LOW AROUSAL          694\n",
      "MODERATE VALENCE HIGH AROUSAL        1064\n",
      "LOW VALENCE MODERATE AROUSAL         1189\n",
      "HIGH VALENCE HIGH AROUSAL            1475\n",
      "HIGH VALENCE MODERATE AROUSAL        1600\n",
      "LOW VALENCE HIGH AROUSAL             2005\n",
      "MODERATE VALENCE MODERATE AROUSAL    2329\n",
      "dtype: int64\n",
      "\n",
      "4 CATEGORIES\n",
      "AROUSAL_VAL_CAT2\n",
      "LOW VALENCE LOW AROUSAL      1604\n",
      "HIGH VALENCE LOW AROUSAL     1789\n",
      "HIGH VALENCE HIGH AROUSAL    3550\n",
      "LOW VALENCE HIGH AROUSAL     4074\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "val_ar_size=y_df.groupby(by='AROUSAL_VAL_CAT').size().sort_values()\n",
    "print('9 CATEGORIES')\n",
    "print(val_ar_size)\n",
    "print()\n",
    "val_ar_size2=y_df.groupby(by='AROUSAL_VAL_CAT2').size().sort_values()\n",
    "print('4 CATEGORIES')\n",
    "print(val_ar_size2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x20d84997908>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_ar_size.plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x20d84f53648>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAD4CAYAAABv2NUXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3debwU1Z338c9XxAU1uCsCilGicUUkLoiOGONu1HEBMkaNkzHOOJlIJokYffKYxYiZGDWbeYzRmEVwR0eNxokQNyKCgiARxXDdYhTNiFtQo7/nj3Mai6bv7brc27db+L5fr37drlPVp351Wqlfn3OqShGBmZmZWT2rNDsAMzMz+2Bw0mBmZmalOGkwMzOzUpw0mJmZWSlOGszMzKyUVZsdgFmjbLjhhjFo0KBmh2Fm9oEyY8aMlyJio1rrnDTYCmvQoEFMnz692WGYmX2gSHqqvXUenjAzM7NSnDSYmZlZKU4azMzMrBQnDWZmZlaKkwYzMzMrxUmDmZmZleKkwczMzEpx0mBmZmalOGkwMzOzUpw0mJmZWSlOGszMzKwUJw1mZmZWih9YZSus2c8tYtC4W5sdhplZj2obf2jD6nZPg5mZmZXipMHMzMxKcdJgZmZmpThpMDMzs1KcNJiZmVkpThrMzMysFCcNZmZmVoqTBjMzMyvFSYOZmZmV0mNJg6TX2yk/RdJj+TVN0ohcfoSkSYXtzpQ0v7B8uKSbq+o6R9J5VWVDJP2xsLyLpJB0YL34cn3PSZpZeK0rad9cx+GFbW+RtG9+31vSeElPSJqTj+vgvK5N0uxCfd9vZ79fqiprk7RhdaySBud9PylphqTJkvbJ606S9MOqeqZIGla9z7xuI0nvSPpcjX3PlvSIpN9L2qKwboCkm/KxPinpYkmrldm/pJML9c6RdERhu1UlvVTj+2w3fjMza6ym9jRIOgz4HDAiIrYFTgWukrQpcD+wZ2HzPYFXJW2cl4cD91VVOQEYVVU2GriqsDwGuDf/LePCiBhSeL2Sy58FzmrnM98E+gE7RMQOwOHAOoX1Iwv1/UfJOJYhaQ3gVuDSiNgqInYFPg98eDmrPBb4A7XbZmRE7ARMAc7O+xdwAzApIgYDHwHWBs4tEfsAUvuNyPXuATxS2OQAYB5wXN6PmZk1WbOHJ84AvhwRLwFExEPAlcBpEbEQWCRp67xtf+B6UrJA/nt/sbKImAe8Imn3QvFxwERYcpI7BjgJOCCfdJfXrBzfJ4qFkvoA/wJ8PiLeynG9EBHXdGFf7fknYGpELOlxiYg5EfHz5axvDPCfwABJ/dvZZirpuwDYD1gcEVfkfb8LjAVOzu3QkY2B14DX82dfj4gFVbFcDDxNSijMzKzJmp00bA/MqCqbnsshJQXDJW0DPEH6FTxc0qrATsCDNeqcQOpdQNIewMsR8URetxewICKeJP1iPqREjGMLQwmTq9Z9i/yru2Br4OmIeLWDOicX6hxbYr8zgc1qbLM98FCd+EdV1dPe0MRAYNOImAZcw7I9NhUHAZVho2W+v3zcT5PaoSOzgBeABZKuqBrqWRP4OHAL6fss2ytkZmYN1OykoRYBkd/fR+pRGE76hTsN2B3YBZgXEYtrfH4icIykVUjJw4TCujF5fWW7Miej4vDEyOKKiLgHQNLeZQ6soDg8cWGJ/Q4B/lyvUkk35rkBNxSKr66qZ3o7Hx9NShagdttMlvQisD/vD/cUv6ulQsnltdYBRO6VOIjU8/M4cKGkc/L6w4DJEfEmqXfpKEm92qlr6R2nOTLTJU1/981FZT5iZmYlNTtpmAvsWlU2NJdD7mnIr6kR8RqwBrAvy85nACAingHagH8AjiafCPNJ52jga5LagB8AB0tap1Y9nXAuS89tmA9s3g31lvEoqb0AiIijSEMv6y9HXWOAk3Lb3AzsLGlwYf1IYIu8z28U9r9Uz4WkDwEDgSeBl4H1qvazPlAZjoqImBYR55GSlqMLseyfY5kBbJD3X1dEXBoRwyJiWK8+fct8xMzMSmp20vAd4HxJG0C60oF00vtxXj+X1C2/N/BwLptJmjC51HyGKhOAC4EnI+LZXLY/MCsiBkbEoIjYgvQr9siuHEBE/JZ0Ytw5L78J/Az4fuEqgn6Sju/KftpxFbCXpE8WyurNJVhGHv5ZKyL657YZBFRO5EtExN+A04ETJK0P/A7oI+mEXE8v4ALg57kdHszxbZrXDwNWB56RtJmkoYXqhwBP5aRjBLB5IZbT8BCFmVnT9WTS0EfSs4XXF/MEvsuB+yU9BvwUOD4inof0SxR4AHgpIt7J9UwlXR3QUdJwLWm8fWKhbAxwY9V21wOfai++XL7U3AJJg2rs71xgQGH5bGAhMFfSHNIcgIWF9cU5Db/o4Dg6lE/ihwGnSvqTpKl539/qZFXttc0yJ+r83UwgTVYN4CjgWElPkIYZFgNfzdu+AHwBuC3Pp7gIGBMR7wG9ge8qXWo7kzSH4gvAPwJ3VSaRZjcBn5S0el6+tfA9XdvJYzUzs+Wk9O++2Ypn9X6Do9+JFzU7DDOzHtU2/tAufV7SjIioOWm+2cMTZmZm9gHhpMHMzMxKcdJgZmZmpThpMDMzs1KcNJiZmVkpThrMzMysFCcNZmZmVoqTBjMzMytl1WYHYNYoO/bvy/Qu3uTEzMze554GMzMzK8VJg5mZmZXipMHMzMxKcdJgZmZmpThpMDMzs1KcNJiZmVkpThrMzMysFCcNZmZmVoqTBjMzMyvFSYOZmZmV4qTBzMzMSnHSYGZmZqU4aTAzM7NSnDSYmZlZKU4azMzMrBQnDWZmZlaKkwYzMzMrxUmDmZmZleKkwczMzErpMGmQNFDSREn3SPqqpN6FdZMaH56ZmZm1ino9DZcDU4DPA/2A30vaIK/booFxmZmZWYtZtc76jSLiJ/n95yUdD9wt6ZNANDY0MzMzayX1kobektaIiMUAEfErSX8B7gDWanh0ZmZm1jLqDU9cBuxeLIiI/wGOBeY0KigzMzNrPfV6Gt6JiN9XF0bEw8AnGhOSmZmZtaJ6PQ0n90gUZmZm1vLq9TSYfWDNfm4Rg8bd2uwwzGwF0jb+0GaH0FT1koadJL1ao1xARMSHGhCTmZmZtaB6ScPsiNilRyIxMzOzlubbSJuZmVkp9ZKGa9tbIelj3RyLmZmZtbAOhyci4tvFZUnbAaOBMcAiYFjjQjMzM7NWUvfqCUlbkJKEMcDfSc+cGBYRbY0NzczMzFpJvadc3g/cBvQGjomIXYHXnDCYmZmtfOrNaVgIrANsAmyUy/ygKjMzs5VQh0lDRBwB7Ag8BHxd0gJgPUm79URwZmZm1jrqzmmIiEXA5cDlkjYGRgEXSRoYEQMbHaCZmZm1hnpzGtaQVBmWICJejIgfAEcBB9SrXNLrVcsnSfphfn+OpC8V1n1R0mOSZkuaJel7knrndW2SNixsu6+kW6rqXkvSy5L6VpVPknRcYfkmSVOrtlkqlkL5u5JmFl7jcvkUSdML2w2TNKWwvJukuyXNy8d0maQ++fgXVtW5XTPbrWo/F0t6TtIqhbJizI9JGlv1mVNy+WOSpkkaUVjX7v4lbSLplhzzXEm3VdU7VtLi4vdZL34zM2usenMavg/sXaN8f+A/uisISaeSkpA9ImJH4GPAi8CaZeuIiDeA3wJHFurtC4wAKieqdYGhwLqStixR7d8iYkjhNb6wbmNJB9c4lk1I97c4IyK2AT4K3E6aGwJwdVWdc8seY419dbndCnWtQkoGnwH2qVp9dUQMAfYCzpI0MH/mMOBzwIiI2BY4FbhK0qYldvkN4M6I2DkitgPGVa0fAzyYYzIzsxZQL2kYERE3VBdGxK9Z9sTSFWcB/xoRr+T6346I8RFR67kXHZlAuo9ExVHA7RHxZl4+GvhvYGLVdsvjv4Cza5SfBlwZEVMhPaAjIq6LiBe6uL9auqvdAEYCc4BLSCfsZUTEy8B8oF8uOgP4ckS8lNc/BFxJaoN6+gHPFup+pPJe0lbA2qT2rRmLmZn1vHpzGtTBujK3oF5T0szC8vrAzUvtQFoHWDsiFtSpa7Kkd/P7tYHHamxzO3CZpA3yCW408IPC+jHA14EXgOuA8zoZ/3kRcXV+PxU4StJI4LXCNjuQTpztGVXswgf2jIi/1dlvo9sNUttMAG4Cvi2pd0S8U7XPzYE1gMoJfntgRlU904ET68QE8CPgakn/DvwPcEVE/LkqlnuAbSRtHBEvlqgTSacApwD0+tBGdbY2M7POqHfif7HWlRL5FtILS9S/VPc+8LUa24jCZZySDszj522Shhe2G1mo57O1dhYRb5NOrsfksfQhpCGLyrDB1sC9EfE48HdJO3Qm/kLCUPEtavc2dKR6eKI6YVhmvzS43SStBhwCTMq9FA+w9JyVUZIeBf4EXBwRizs4vmJctS7PDYCIuAP4MPBTYFvgYb0/f2Y0MDEi3gNuAI7tYH9LVx5xaUQMi4hhvfr0rf8BMzMrrV7S8GXgmjz57vD8+jpwTV7XZfkk9UZljkFE3JFPcHOA1ZajysoQxTHATYVfy6OA9YAFktqAQXRxiCIi7iL98t6jUPwosGtX6i257+5st4OAvsDs3DYjWHpY4OqI2J40v+WCwpyFuSx7rENzOcDLpDavWB94qXAMf42IqyLi06T5C/tI2gkYDNyZY6ncttzMzJqs3n0apgG7kX49npRfAnaPiAe6MY7zgEvyREUkiXQyXh6TSSed00gJRMUY4KCIGBQRg0gnu67OawA4F/hKYfmHwImSdq8USDq+5OTAzuqudhsDfLbQNlsCB0jqU9woz9P4JfCFXPQd4HxJG+T9DyH9N/LjvH4K8Om8rhdwPOn7QdJ+lfrzUMtWwNM5lnMqsUTEZkB/pduZm5lZE5W5T8OLwP/taBtJ10fE0V2I4xKgD/CApLeA14H7gIc7W1FEvCfpelKX9t05vkHA5sAfCtstkPRq4eR+tqTTC+sHsOzcgtsjYqlZ/hFxm6SFheUXJI0Gvqt0X4v3chyVCaXVcxr+LSLu7+xxZl1ut3ziPpB0FUTlGN6QdC9weI2PnA88JOnbEXGzpP7A/ZKCNLfj+Ih4Pm/7TVJSM4uUbN4O/Cqv2xX4oaS/k5LXyyLiQUnXANVXpdxISvAeAD4u6dnCumMrk07NzKyxFNH1u0JLejgidumGeMy6zer9Bke/Ey9qdhhmtgJpG39os0NoOEkzIqLmU6zLXAFRhp9HYWZmtoLrrqTBzMzMVnDdlTR0dD8HMzMzWwEsd9IgqXjPgjO6IRYzMzNrYV3padiz8iYiftsNsZiZmVkL85wGMzMzK6XD+zRIGtreKqB394djZmZmrarezZ0u6GBdew8+MmsJO/bvy/SV4JpqM7Oe0mHSEBEj21snyT0NZmZmK5FOzWlQsp+ky4Bn637AzMzMVhilkgZJu0u6GHiK9Ojpe0iPMzYzM7OVRIdJg6RzJT0BfBuYDewCLIyIKyPif3siQDMzM2sN9SZCngLMIz1N8ZaIWJyfZmhmZmYrmXrDE5sC5wKfBOZL+iXpcdF1H6ltZmZmK5Z6V0+8C/wG+I2kNYDDgD7Ac5J+FxGf6oEYzczMrAXUm9OwSeV9RCyOiOsi4mhgMHBHo4MzMzOz1lFveGKWpDslnSypb6UwIl6NiCsbHJuZmZm1kHpJQ3/gu8DewOOSJkkaJWnNxodmZmZmraTDpCEi3o2IOyLiM8BA4ArgSGCBpF/3RIBmZmbWGkrfETIi3gbmAn8EXgW2a1RQZmZm1nrqJg2SNpf0ZUkPAbcAvYAjImKXhkdnZmZmLaPeo7HvJ81ruBY4JSKm90hUZmZm1nLq3aTpTODuiOjwLpCSzoyI87ovLDMzM2s19SZC/r5ewpAd203xmJmZWYvq1KOxO6BuqsfMzMxaVHclDX6IlZmZ2QrOPQ1mZmZWynInDZJOLyxe2w2xmJmZWQvrSk/DFytvIuLb3RCLmZmZtbCuJA0ekjAzM1uJdCVp8ORHMzOzlUi9O0K+Ru3kQECfhkRkZmZmLanDpCEi1umpQMzMzKy1dXp4QtJakv5J0q2NCMjMzMxaU6mkQdJqko6UdA3wPLA/8JOGRmZmZmYtpd6chk8AY4ADgcnAL4HdIuIzPRCbWZfMfm4Rg8a5Q8zKaRt/aLNDMGt59Z5yeQdwDzAiIhYASLq44VGZmZlZy6mXNOwKjAb+R9KfgIlAr4ZHZWZmZi2n3qOxH46IMyJiK+AcYBdgNUm/kXRKTwRoZmZmraH01RMRcV9E/DvQH7gQ2LNhUZmZmVnLqTcRcgvglYhYlJdHAkcCTwGfa3x4ZmZm1irq9TRcA6wFIGkI6WmWTwM7Az9qbGhmZmbWSupNhFwzIv6c3x8PXB4RF0haBZjZ2NDMzMysldTraSg+yXI/4HcAEfFewyIyMzOzllSvp+Guwl0g1wPuApDUD3i7wbGZmZlZC6nX03A6cAPQRrrB0zu5fFPgrM7sSNLrVcsnSfphfn+OpC8V1n1R0mOSZkuaJel7knrndW2SNixsu6+kW6rqXkvSy5L6VpVPknRcYfkmSVOrtlkqlkL5u5JmFl7jcvkUSdML2w2TNKWwvJukuyXNy8d0maQ++fgXVtW5Xb12K5Sfkut7TNI0SSNy+RGSJhW2O1PS/MLy4ZJubqfOjSS9I+lzVeVt+bt4RNLv8wTZyroBuR2fkPSkpIslrZbXLfmOC9tPkTQsvz+5UO8cSUcUtltV0kuSzmvv82Zm1rPq3achImJiRFwYEc8Vyh+OiDsaEZCkU4EDgD0iYkfgY8CLwJpl64iIN4Dfkq70qNTbFxgB3JKX1wWGAutK2rJEtX+LiCGF1/jCuo0lHVzjWDYhTR49IyK2AT4K3A5Unh56dVWdc8scn6TDSFevjIiIbYFTgaskbQrcz9KXw+4JvCpp47w8HLivnaqPBf5AunV4tZERsRMwBTg7xyFSUjkpIgYDHwHWBs4tcQwDSInniFzvHsAjhU0OAOYBx+X9mJlZk3WYNEh6TdKrhdei/GvyMkkbNCims4B/jYhXACLi7YgYHxGvdrKeCaS7WVYcBdweEW/m5aOB/ybd5XI0XfNf5BNpldOAKyNiKixJwq6LiBe6uL8zgC9HxEu53oeAK4HTImIhsEjS1nnb/sD1pGSB/Pf+duodA/wnMEBS/3a2mZrrhDTPZXFEXJHjeBcYC5wsqU+dY9gYeA14PX/29cqtyguxXEy6WmePOnWZmVkPqNfTsE5EfKjw6gsMAx6l80+5XLPYFQ98o3oDSesAa1edPGqZXKjnsna2uR3YtZDcjCYlEhVj8vIEav+y7jB+SaMK66YCb+X7WBTtAMzooM5RVXWW7U3Zvka903M5pKRguKRtgCdIvQfDJa0K7AQ8WF2hpIHAphExjXSp7ajqbbKDgMrwxzJx5OTuaWBrOjYLeAFYIOkKSYcXYlkT+DipV6js91P57CmSpkua/u6bi8p+zMzMSih9R8iKiPjfiLgQ2KqTH12qex/4Wo1tBMSSBenAfDJtkzS8sN3IQj2fbSfOt4GbgWPyHIghpCGLyrDB1sC9EfE48HdJO3Qm/oi4umr9t6jd29CR6uGJv3Xy80XFtruP1KMwnJTQTAN2J90GfF5ELK7x+dGkZAFS70v1iXqypBdJj0W/qsY+a8VSax2kTpd3SQnIMcDjwIWSzsnrDwMm516h64GjJJV65klEXBoRwyJiWK8+fet/wMzMSut00gCgNCmx3pUXnZZ/pb5RmWMQEXfkxGAOsNpyVFkZojgGuKkwkXMU6WqQBZLagEF0cYgiIu4C1mDprvRHSQ/96m5za9Q7NJdD7mnIr6kR8VqObV/an88wBjgpt8fNwM6SBhfWjwS2IB1TpZfoUVLP0xKSPgQMBJ4EXia1c9H6QGVYJSJiWkScR2r/owux7J9jmQFskPdvZmZNVG9Owz/WeP0zcCtwXYNiOg+4JE9UrEy2W2M565oMDCbNLagemjgoIgZFxCDef5pnV50LfKWw/EPgREm7VwokHZ8nLHbFd4DzK0MvSnfrPAn4cV4/F9gM2Bt4OJfNJE2YXGY+Qx7GWCsi+hfapHIiXyL3hJwOnCBpfdJ9O/pIOiHX0wu4APh57iV4ENircrz5qofVgWckbSZpaKH6IcBTOekYAWxeiOU0OjFEYWZmjVGvt+DwquUg/Xq8OCJubUxIXAL0AR6Q9BZpotx9vH/yKy0i3pN0PemqgLsBJA0CNieN81e2W5AnelZO7mdLOr2wfgB5TkOh+tsjYlzV/m6TtLCw/IKk0cB389UL7+U4bsibjFK+VDL7t4ioPqn3kfRsYfl7EfG9PFHxfklBmlB4fEQ8n/cbkh4A+hZ6V6YCp1B7EuQY4MaqsutJwxTfrDrG5yVNIE26/Kako4AfS/o/pCT0NuCrheP/AnCb0l1EXwfG5O+ld26XzYDFwEJSUvOPwF0R8VZhtzcB35G0el6+VdKS44qIY2sck5mZdTNFtDfsbPbBtnq/wdHvxIuaHYZ9QLSNP7TZIZi1BEkzIqLm/XDqzmmQdLDSzYleUroZ0e8lHdL9YZqZmVkrq/do7H8h3UToK6RL+iBNfBsvaUBEXNrg+MzMzKxF1JvTMJZ0x76/Fsruync/vBdw0mBmZraSqPuUy6qEAYCIeLlB8ZiZmVmLqpc0vCpp5+rCXPZaY0IyMzOzVlRveOI/gZslXUG6yU6QHiB1InB8g2MzMzOzFlLv2RP3km4/vArp5kEn5/d75HVmZma2kqh7K+iI+As1nhMhaa+IaO+WxGZmZraCqXfJZS/gONKjkH8TEY9KOox0x781SQ9AMmtJO/bvy3TfsMfMrNvU62n4GenhQ9OAH0h6CtgTGBcRkzr8pJmZma1Q6iUNw4Cd8rMC1iA9nXDrPGRhZmZmK5F6l1y+HRHvAUTEYuBxJwxmZmYrp3o9DdtKeiS/F7BVXhbwXkQscw8HMzMzWzHVSxo+WqNMwADy44/NzMxs5dBh0hART1XeSxoCfIp0NcUC4PrGhmZmZmatpN4llx8BRgNjgJeBq0nPoxjZA7GZmZlZC6k3PPEYcA9weETMB5A0tuFRmZmZWcupd/XE0cBfgMmSfirp46Q5DWZmZraSqffsiRsjYhSwLTAFGAtsIukSSQf0QHxmZmbWIur1NAAQEW9ExK8j4jDSlRMzgXENjczMzMxaSqmkoSgi/hoR/y8i9mtEQGZmZtaaOp00mJmZ2crJSYOZmZmV4qTBzMzMSnHSYGZmZqU4aTAzM7NSnDSYmZlZKU4azMzMrBQnDWZmZlaKkwYzMzMrxUmDmZmZleKkwczMzEpx0mBmZmalOGkwMzOzUpw0mJmZWSmrNjsAs0aZ/dwiBo27tdlhWA9rG39os0MwW2G5p8HMzMxKcdJgZmZmpThpMDMzs1KcNJiZmVkpThrMzMysFCcNZmZmVoqTBjMzMyvFSYOZmZmV4qTBzMzMSunxpEHS6+2UnyLpsfyaJmlELj9C0qTCdmdKml9YPlzSzVV1nSPpvKqyIZL+WFjeRVJIOrBefLm+5yTNLLzWlbRvruPwwra3SNo3v+8tabykJyTNycd1cF7XJml2ob7vt7PfL9UoHyDpplzvk5IulrRaXvewpCH5/aqS3pB0fOGzMyQNXeYLSOsuzse5SqHsJEkLc4yPSRpb9Zma31vhGDcsLO8r6Zb8fpPcVrMkzZV0W1W9YyUtltS31ufNzKzntURPg6TDgM8BIyJiW+BU4CpJmwL3A3sWNt8TeFXSxnl5OHBfVZUTgFFVZaOBqwrLY4B7898yLoyIIYXXK7n8WeCsdj7zTaAfsENE7AAcDqxTWD+yUN9/lAlCkoAbgEkRMRj4CLA2cG7e5H5SmwDsDMyrLEtaC/gwMKtGvasARwHPAPtUrb46IoYAewFnSRqYP9PR91bPN4A7I2LniNgOGFe1fgzwYI7JzMxaQEskDcAZwJcj4iWAiHgIuBI4LSIWAoskbZ237Q9cz/snxuGkE+USETEPeEXS7oXi44CJsOTEewxwEnCApDW6EPusHN8nioWS+gD/Anw+It7Kcb0QEdd0YV8A+wGLI+KKXOe7wFjg5LzP+1i6bX4CDMnLuwEP5c9UGwnMAS6hnUQqIl4G5pMSIejgeytxHP1ICVel7kcq7yVtRUqEzm4vFjMz63mtkjRsD8yoKpueyyH/epa0DfAE8Ie8vCqwE+kXabUJpN4FJO0BvBwRT+R1ewELIuJJYApwSIkYxxaGEiZXrfsW6QRXtDXwdES82kGdkwt1ju1gu6Jl2irv4+m8z2JPw3DgbuAtSetQu1emYgypzW4EDpPUu3oDSZsDawCVE3y9760jPwJ+JmmypLMkbVYjlnuAbQq9SmZm1kStkjTUIiDy+8qv5+HAVGAasDuwCzAvIhbX+PxE4Jjc7T6adBKqGJPXV7Yr82u2ODwxsrgiIu4BkLR3mQMrKA5PXFjyM8V2WaY8ItqA1fIQwbak4YkHSe21TK9Mjns1UuI0KScgDwAHFDYZJelR4E/Axe20d634asUZpEDvIA2V/DTH+bCkjfI2o4GJEfEeaSjm2A72V30sp0iaLmn6u28uKvsxMzMroVWShrnArlVlQ3M5vP/reTgwNSJeI/3i3Zd2fjlHxDNAG/APwNHANQCSeuXlr0lqA34AHJx/iXfFuSw9t2E+sHk31FvtUWBYsUDSh4CBwJO5aCpp+OX5iAhSz8xepOGJP9So8yCgLzA7t8kIlk6kro6I7YG9gQsKcxbqfW8vA+sV1q0PvFRZiIi/RsRVEfFpUmKzj6SdgMHAnTmW0XRiiCIiLo2IYRExrFefvvU/YGZmpbVK0vAd4HxJG0C60oE03+DHef1cYDPSSevhXDaTNPFumV/OBROAC4EnI6Iyfr4/MCsiBkbEoIjYgjRH4siuHEBE/JZ0gtw5L78J/Az4fuHKhn7FKxmW0++APpJOyHX2Ai4Afp73CSmRGktKHsh/TwD+UpjAWTQG+Gxuj0HAlqS5Hn2qjnEq8EvgC7mo3vc2Bfh0Ic7jgcl5eb9K/Tmx2oo0xDIGOKcSS0RsBvSXtEUn28nMzLpZM5KGPpKeLby+GBE3A5cD90t6jNRlfXxEPA+pz53UZZ6NsqcAAAbnSURBVP5SRLyT65lK6t7uKGm4ljS+PrFQNoY0bl90PfCp9uLL5cU5DTMlDaqxv3OBAYXls4GFwFxJc4BJebmiOKfhF+0cw9nFeHJbHAUcK+kJ4HFgMfDVwmfuI7XNVIDcjr2oPTTRBzgQuLVSFhFvkK4sObx6e+B84DOS1qn3vZGuHtla0ixSsjcf+FVetyswXdIjOc7LIuJBUs9C9fdzYy4H+HjV97MnZmbWI5TOQWYrntX7DY5+J17U7DCsh7WNP7TZIZh9oEmaERHDaq1rleEJMzMza3FOGszMzKwUJw1mZmZWipMGMzMzK8VJg5mZmZXipMHMzMxKcdJgZmZmpThpMDMzs1JWbXYAZo2yY/++TPeNfszMuo17GszMzKwUJw1mZmZWipMGMzMzK8VJg5mZmZXipMHMzMxKcdJgZmZmpThpMDMzs1KcNJiZmVkpThrMzMysFCcNZmZmVoqTBjMzMyvFSYOZmZmV4qTBzMzMSlFENDsGs4aQ9Bowr9lxtGND4KVmB9GBVo7PsS0fx7Z8VsbYtoiIjWqt8KOxbUU2LyKGNTuIWiRNb9XYoLXjc2zLx7EtH8e2NA9PmJmZWSlOGszMzKwUJw22Iru02QF0oJVjg9aOz7EtH8e2fBxbgSdCmpmZWSnuaTAzM7NSnDSYmZlZKU4abIUk6SBJ8yTNlzSuSTG0SZotaaak6blsfUl3Snoi/10vl0vS93O8j0ga2s2xXC7pRUlzCmWdjkXSiXn7JySd2MDYzpH0XG67mZIOKaw7M8c2T9KBhfJu/84lDZQ0WdIfJT0q6Qu5vOlt10FsTW87SWtImiZpVo7t67l8S0kP5Da4WtJquXz1vDw/rx9UL+YGxPZzSQsK7TYkl/fo/w+53l6SHpZ0S15uerstERF++bVCvYBewJPAh4HVgFnAdk2Iow3YsKrsO8C4/H4ccH5+fwjwG0DAHsAD3RzLPsBQYM7yxgKsD/wp/10vv1+vQbGdA3ypxrbb5e9zdWDL/D33atR3DvQDhub36wCP5xia3nYdxNb0tsvHv3Z+3xt4ILfHNcDoXP4T4F/z+38DfpLfjwau7ijmBsX2c+CYGtv36P8Pue4vAlcBt+Tlprdb5eWeBlsR7QbMj4g/RcTbwETgiCbHVHEEcGV+fyVwZKH8F5H8AVhXUr/u2mlE3A38tYuxHAjcGRF/jYj/Be4EDmpQbO05ApgYEW9FxAJgPun7bsh3HhHPR8RD+f1rwB+B/rRA23UQW3t6rO3y8b+eF3vnVwD7Adfl8up2q7TndcDHJamDmBsRW3t69P8HSQOAQ4HL8rJogXarcNJgK6L+wDOF5Wfp+B/TRgngt5JmSDoll20SEc9D+kcf2DiXNyPmzsbS0zH+e+4OvrzS/d/M2HLX7y6kX6Yt1XZVsUELtF3uYp8JvEg6oT4JvBIRf6+xnyUx5PWLgA16KraIqLTbubndLpS0enVsVTE06ju9CPgK8F5e3oAWaTdw0mArJtUoa8a1xXtFxFDgYOA0Sft0sG2rxAztx9KTMV4CbAUMAZ4HLsjlTYlN0trA9cDpEfFqR5u2E0fD4qsRW0u0XUS8GxFDgAGkX7kf7WA/TY1N0g7AmcC2wMdIQw5n9HRskg4DXoyIGcXiDvbT4/+9OWmwFdGzwMDC8gDgzz0dRET8Of99EbiR9A/nC5Vhh/z3xbx5M2LubCw9FmNEvJD/YX8P+Cnvd632eGySepNOyr+OiBtycUu0Xa3YWqntcjyvAFNI8wHWlVR55lFxP0tiyOv7koaseiq2g/JwT0TEW8AVNKfd9gI+KamNNEy0H6nnoWXazUmDrYgeBAbnGcerkSYI3dyTAUhaS9I6lffAAcCcHEdllvWJwE35/c3ACXmm9h7Aokr3dwN1NpY7gAMkrZe7vA/IZd2uaj7HUaS2q8Q2Os8a3xIYDEyjQd95Hh/+GfDHiPheYVXT26692Fqh7SRtJGnd/H5NYH/SnIvJwDF5s+p2q7TnMcBdkWb0tRdzd8f2WCEJFGnOQLHdeuQ7jYgzI2JARAwifQ93RcQ/0QLtVgzSL79WuBdpxvPjpHHUs5qw/w+TZi/PAh6txEAab/wd8ET+u34uF/CjHO9sYFg3xzOB1FX9DulXyD8vTyzAyaRJVfOBzzQwtl/mfT+S/wHsV9j+rBzbPODgRn7nwAhSt+4jwMz8OqQV2q6D2JredsBOwMM5hjnA1wr/X0zLbXAtsHouXyMvz8/rP1wv5gbEdldutznAr3j/Cose/f+hUPe+vH/1RNPbrfLybaTNzMysFA9PmJmZWSlOGszMzKwUJw1mZmZWipMGMzMzK8VJg5mZmZXipMHMzMxKcdJgZmZmpfx/6jaAL50Mi6sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_ar_size2.plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_lst=[\n",
    "    (emo_only_df,'emotion only'),\n",
    "    (emo_personality_df, 'emotion + personality'),\n",
    "    (stat_cat_pers_df, 'stat distanes + emotion labels')\n",
    "]\n",
    "\n",
    "input_lst_transform=[]\n",
    "for X,name in input_lst:\n",
    "    X=X.to_numpy()\n",
    "    scaler=StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X=scaler.transform(X)\n",
    "    res=(X,name)\n",
    "    input_lst_transform.append(res)\n",
    "\n",
    "output_lst=[\n",
    "    (y_df[['VAL_AR_NUM']].to_numpy(),'9 Categories'),\n",
    "    (y_df[['VAL_AR_NUM2']].to_numpy(),'4 Categories')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units=[5,10,15,20,30,40,50]\n",
    "epochs=[20,40]\n",
    "\n",
    "\n",
    "def NN_classifier(n_inputs, n_outputs,unit):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(unit, input_dim=n_inputs, kernel_initializer='he_uniform', activation='relu'))\n",
    "    model.add(Dense(n_outputs,activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "with open('NeuralNetClassifier.txt', 'w') as file:\n",
    "            file.write('Classification Approach:\\nNEURAL NETWORK- 2 dense layers (input and output)')\n",
    "\n",
    "for input_,name_i in input_lst_transform:\n",
    "    for output,name_o in output_lst:\n",
    "        y=to_categorical(output)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(input_, y, test_size = 0.2, random_state = 42)\n",
    "        with open('NeuralNetClassifier.txt', 'a') as file:\n",
    "                    file.write('\\n Input used: {},\\noutput used: {}'.format(name_i,name_o))\n",
    "        for unit in units:\n",
    "            for epoch_n in epochs:\n",
    "                model=NN_classifier(X_train.shape[1], y_train.shape[1],unit)\n",
    "                history = model.fit(X_train, y_train, validation_split=0.2, epochs =epoch_n,verbose=0)\n",
    "                loss_neural, acc_neural = model.evaluate(X_test, y_test)\n",
    "                with open('NeuralNetClassifier.txt', 'a') as file:\n",
    "                    file.write(\"\"\"\\n\\n\\t Configuration: {} units, {} epochs\n",
    "                                   \\n\\t\\t Loss: {}\\n\\t\\t Accuracy: {}\"\"\".format(unit,epoch_n,loss_neural,acc_neural))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc = history.history['accuracy']\n",
    "# val_acc = history.history['val_accuracy']\n",
    "# plt.plot(epochs, acc, 'y', label='Training accuracy')\n",
    "# plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
    "# plt.title('Training and validation accuracy')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 500, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 10)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "best_random_lst=[]\n",
    "for input_,name_i in input_lst_transform:\n",
    "    for output,name_o in output_lst:\n",
    "        output=to_categorical(output)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(input_, output, test_size = 0.2, random_state = 42)\n",
    "\n",
    "        rf = RandomForestClassifier()\n",
    "        rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 5, \n",
    "                                       verbose=1, random_state=42, n_jobs = -1)\n",
    "        rf_random.fit(X_train, y_train)\n",
    "        res=(name_i,name_o,rf_random.best_estimator_)\n",
    "        best_random_lst.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('RandomForestClassification.txt', 'w') as file:\n",
    "    file.write(\"RandomForestClassification\")\n",
    "\n",
    "\n",
    "for name_in_best,name_out_best, model in best_random_lst:\n",
    "    for data_in,ds_name_in in input_lst_transform:\n",
    "        if ds_name_in == name_in_best:\n",
    "            X = data_in\n",
    "\n",
    "    for data_out,ds_name_out in output_lst:\n",
    "        if ds_name_out == name_out_best:\n",
    "            y = data_out\n",
    "\n",
    "    y=to_categorical(y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "    with open('RandomForestClassification.txt', 'a') as file:\n",
    "        file.write(\"\\n\\nInput data used: {}\\noutput data used: {}\\nmodel parameters used: {}\\n\\n\".format(name_in_best,name_out_best,model))\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_RF = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred_RF)\n",
    "    with open('RandomForestClassification.txt', 'a') as file:\n",
    "        file.write(\"Results\\n\\t'Accuracy using Random Forest: {}\".format(acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining parameter range\n",
    "#Setting C: C is 1 by default and it’s a reasonable default choice. If you have a lot of noisy observations you should decrease it:\n",
    "# it takes forever for 'linear' kernel+big values of C so not going to try it \n",
    "#One is advised to use GridSearchCV with C and gamma spaced exponentially far apart to choose good values.\n",
    "param_grid = {'C': [0.001,0.1, 1, 10, 100], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001,'scale','auto'],\n",
    "              'kernel': ['rbf','sigmoid'],\n",
    "              'class_weight':['balanced',None]} \n",
    "\n",
    "best_estimator_lst = []\n",
    "for input_,name_i in input_lst_transform:\n",
    "    for output,name_o in output_lst:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(input_, output.ravel(), test_size = 0.2, random_state = 42)\n",
    "        grid = GridSearchCV((SVC()), param_grid, cv=5, verbose = 3,n_jobs=-1)\n",
    "        grid.fit(X_train, y_train)\n",
    "        res=(name_i,name_o,grid.best_estimator_)\n",
    "        best_estimator_lst.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SupportVectorClassification.txt', 'w') as file:\n",
    "    file.write(\"SupportVectorClassification\")\n",
    "\n",
    "\n",
    "for name_in_best,name_out_best, model in best_estimator_lst:\n",
    "    for data_in,ds_name_in in input_lst_transform:\n",
    "        if ds_name_in == name_in_best:\n",
    "            X = data_in\n",
    "    for data_out,ds_name_out in output_lst:\n",
    "        if ds_name_out == name_out_best:\n",
    "            y = data_out       \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y.ravel(), test_size = 0.2, random_state = 42)\n",
    "    with open('SupportVectorClassification.txt', 'a') as file:\n",
    "        file.write(\"\\n\\nInput data used: {}Output data used: {}\\nmodel parameters used: {}\\n\\n\".format(name_in_best,name_out_best,model))\n",
    "           \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_SVM = model.predict(X_test)\n",
    "    acc=accuracy_score(y_test, y_pred_SVM)\n",
    "    with open('SupportVectorClassification.txt', 'a') as file:\n",
    "        file.write(\"Results\\n\\tAccuracy using SVM: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dummy y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_lst=[\n",
    "    (emo_only_df,'emotion only'),\n",
    "    (emo_personality_df, 'emotion + personality'),\n",
    "    (stat_cat_pers_df, 'stat distanes + emotion labels')\n",
    "]\n",
    "\n",
    "input_lst_transform=[]\n",
    "for X,name in input_lst:\n",
    "    X=X.to_numpy()\n",
    "    scaler=StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X=scaler.transform(X)\n",
    "    res=(X,name)\n",
    "    input_lst_transform.append(res)\n",
    "\n",
    "output_lst=[\n",
    "    (y_df[['VAL_AR_NUM']].to_numpy(),'9 Categories'),\n",
    "    (y_df[['VAL_AR_NUM2']].to_numpy(),'4 Categories')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf', max_iter=-1,\n",
       "    probability=False, random_state=None, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(input_lst_transform[1][0], output_lst[1][0].ravel(), test_size = 0.2, random_state = 42)\n",
    "\n",
    "sv=SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf', max_iter=-1,\n",
    "    probability=False, random_state=None, shrinking=True, tol=0.001,\n",
    "    verbose=False)\n",
    "sv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_y= np.full((2204, 1), 1, dtype=int)\n",
    "\n",
    "y_pred_SVM = sv.predict(X_test)\n",
    "acc=accuracy_score(y_test, dummy_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3938294010889292"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
